{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31bc7e0d",
      "metadata": {
        "id": "31bc7e0d"
      },
      "source": [
        "# Structure de données\n",
        "nous allons créer les structure RDD et Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a29ee1f2",
      "metadata": {
        "id": "a29ee1f2"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "803dfd5b",
      "metadata": {
        "id": "803dfd5b"
      },
      "outputs": [],
      "source": [
        "# conf\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"Datastructure\")\n",
        "sc = SparkContext.getOrCreate(conf = conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97466447",
      "metadata": {
        "id": "97466447"
      },
      "source": [
        "## Creation d'un RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "464adf4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "464adf4b",
        "outputId": "46fbe50f-1754-4876-9327-21628742f4e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[2] at readRDDFromFile at PythonRDD.scala:289"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "liste = (1,2,5,6)\n",
        "rdd = sc.parallelize(liste)\n",
        "display(rdd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ed416c",
      "metadata": {
        "id": "35ed416c"
      },
      "source": [
        "## Creation d'un dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = SparkSession.builder.appName(\"Datastructure session\").getOrCreate()"
      ],
      "metadata": {
        "id": "jvdM0yO1Ne3i"
      },
      "id": "jvdM0yO1Ne3i",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ef9b5e1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ef9b5e1f",
        "outputId": "9afd0896-9d86-4d79-e27f-d2340288faaa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: string]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Création d'un dataframe\n",
        "data = [(\"John Doe\", \"30\"), (\"Jane Doe\", \"25\")]\n",
        "columns = [\"Name\", \"Age\"]\n",
        "df = session.createDataFrame(data, schema=columns)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5d77315c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5d77315c",
        "outputId": "630f6f79-fd18-48f4-a83b-4e03d5db3c36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: bigint]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Création d'un dataframe avec les colonnes directement\n",
        "df = session.createDataFrame([(\"John Doe\", 30), (\"Jane Doe\", 25)], [\"Name\", \"Age\"])\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "30df21fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "30df21fe",
        "outputId": "bc2ca553-9a58-4b83-d8f4-af1c2ddc651a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/usr/local/lib/python3.10/dist-packages/pyspark/python/pyspark/sql/tests/data/csv/test.csv.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-2680068331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a sample dataset that exists in the Colab environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcsdfvDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file:///usr/local/lib/python3.10/dist-packages/pyspark/python/pyspark/sql/tests/data/csv/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcsdfvDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsdfvDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/usr/local/lib/python3.10/dist-packages/pyspark/python/pyspark/sql/tests/data/csv/test.csv."
          ]
        }
      ],
      "source": [
        "# Create a small sample DataFrame directly\n",
        "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\n",
        "columns = [\"Name\", \"ID\"]\n",
        "csdfvDF = session.createDataFrame(data, schema=columns)\n",
        "csdfvDF.printSchema()\n",
        "csdfvDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9b23c7",
      "metadata": {
        "id": "0e9b23c7"
      },
      "source": [
        "## Creation d'un Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a956c8",
      "metadata": {
        "id": "61a956c8"
      },
      "outputs": [],
      "source": [
        "# Uniquement disponible en java et scala"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a4889a",
      "metadata": {
        "id": "d1a4889a"
      },
      "source": [
        "## API Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c2594d",
      "metadata": {
        "id": "a2c2594d"
      },
      "outputs": [],
      "source": [
        "import pyspark.pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0c7fad",
      "metadata": {
        "id": "ed0c7fad"
      },
      "outputs": [],
      "source": [
        "pandasDataframe = pd.DataFrame(\n",
        "    {'a': [1, 2, 3, 4, 5, 6],\n",
        "     'b': [100, 200, 300, 400, 500, 600],\n",
        "     'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]},\n",
        "    index=[10, 20, 30, 40, 50, 60])\n",
        "pandasDataframe.describe()\n",
        "type(pandasDataframe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pyspark_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.23"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}